{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms.functional import crop\n",
    "from torchvision.io import read_image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from metric_learning.datasets import split_train_test\n",
    "\n",
    "seed = 123\n",
    "train_classes_frac = 0.7\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation\n",
    "\n",
    "First we convert a bunch of json's to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metric_learning.datasets import convert_dataset\n",
    "#convert_dataset(ann_dir=\"data/validation/annos/\", output_path=\"deepfashion_val.csv\")\n",
    "#convert_dataset(ann_dir=\"data/train/annos/\", output_path=\"deepfashion_train.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFashionDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, target_transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[[idx]]\n",
    "        image = Image.open(row['image_path'].values[0])\n",
    "        bbox = row['x_1'].values[0], row['x_2'].values[0], row['y_1'].values[0], row['y_2'].values[0]\n",
    "        cropped_image = image.crop((bbox[0], bbox[2], bbox[1], bbox[3]))\n",
    "        label = row['label'].values[0]\n",
    "        if self.transform:\n",
    "            cropped_image = self.transform(cropped_image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return cropped_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grk\\AppData\\Local\\Temp\\ipykernel_8832\\3858076790.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['label'] = df_train.groupby(['label']).ngroup()\n"
     ]
    }
   ],
   "source": [
    "# read dataframes\n",
    "#df_train = pd.read_csv(\"deepfashion_train.csv\")\n",
    "#df_val = pd.read_csv(\"deepfashion_val.csv\")\n",
    "\n",
    "\n",
    "# for quick tests we use one dataframe and split it into test and val\n",
    "df = pd.read_csv(\"deepfashion_val.csv\")\n",
    "df_train, df_val = split_train_test(df, train_classes_frac, seed)\n",
    "num_classes_train = len(df_train.label.unique())\n",
    "# reassign class numbers so it doesn't go over num_classes_train\n",
    "df_train['label'] = df_train.groupby(['label']).ngroup()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from pytorch_metric_learning import distances, losses, miners, reducers, testers\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 2, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 2, 1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, 2, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.fc1 = nn.Linear(65536, 512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from pytorch_metric_learning import losses, testers\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "\n",
    "\n",
    "def train(model, loss_func, device, train_loader, optimizer, loss_optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss_optimizer.zero_grad()\n",
    "        embeddings = model(data)\n",
    "        loss = loss_func(embeddings, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\"Epoch {} Iteration {}: Loss = {}\".format(epoch, batch_idx, loss))\n",
    "\n",
    "\n",
    "def get_all_embeddings(dataset, model):\n",
    "    tester = testers.BaseTester(dataloader_num_workers=0, batch_size=batch_size)\n",
    "    return tester.get_all_embeddings(dataset, model)\n",
    "\n",
    "\n",
    "### compute accuracy using AccuracyCalculator from pytorch-metric-learning ###\n",
    "def test(query_dataset, retrieval_dataset, model, accuracy_calculator):\n",
    "    query_embeddings, query_labels = get_all_embeddings(query_dataset, model)\n",
    "    retrieval_embeddings, retrieval_labels = get_all_embeddings(retrieval_dataset, model)\n",
    "    query_labels = query_labels.squeeze(1)\n",
    "    retrieval_labels = retrieval_labels.squeeze(1)\n",
    "    print(\"Computing accuracy\")\n",
    "    accuracies = accuracy_calculator.get_accuracy(\n",
    "        query_embeddings, query_labels, retrieval_embeddings, retrieval_labels, False\n",
    "    )\n",
    "    print(\"Test set accuracy (Precision@1) = {}\".format(accuracies[\"precision_at_1\"]))\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "train_dataset = DeepFashionDataset(df_train, transform=train_transform)\n",
    "val_dataset = DeepFashionDataset(df_val, transform=val_transform)\n",
    "# we need to split val dataset for query and retrieval sets\n",
    "# let's just take evens and odds for the first test\n",
    "#!!!!!!!!!!!!!!!!! SAME CLASS SHOULD BE IN BOTH SETS\n",
    "evens = list(range(0, len(val_dataset), 2))\n",
    "odds = list(range(1, len(val_dataset), 2))\n",
    "query_dataset = Subset(val_dataset, evens)\n",
    "retrieval_dataset = Subset(val_dataset, odds)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "loss_func = losses.SubCenterArcFaceLoss(num_classes=num_classes_train, embedding_size=512).to(device)\n",
    "loss_optimizer = torch.optim.Adam(loss_func.parameters(), lr=1e-4)\n",
    "accuracy_calculator = AccuracyCalculator(include=(\"precision_at_1\",), k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "test(query_dataset, retrieval_dataset, model, accuracy_calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Iteration 0: Loss = 41.23060989379883\n",
      "Epoch 1 Iteration 100: Loss = 40.19734191894531\n",
      "Epoch 1 Iteration 200: Loss = 39.61499786376953\n",
      "Epoch 1 Iteration 300: Loss = 39.23011016845703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(model, loss_func, device, train_loader, optimizer, loss_optimizer, epoch)\n",
    "    test(query_dataset, retrieval_dataset, model, accuracy_calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3136"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7*7*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sqrt(61504 / 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
